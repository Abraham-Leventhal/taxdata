{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove aggregate rows, replace NaN with 0\n",
    "\n",
    "puf = pd.read_csv('puf2011.csv')\n",
    "\n",
    "puf = puf[(puf['RECID'] != 999996) &\n",
    "          (puf['RECID'] != 999997) &\n",
    "          (puf['RECID'] != 999998) &\n",
    "          (puf['RECID'] != 999999)\n",
    "         ]\n",
    "           \n",
    "puf = puf.fillna(0)\n",
    "\n",
    "#  MARS to K - 1 dummies\n",
    "\n",
    "puf[['MARS2', 'MARS3', 'MARS4']] = pd.get_dummies(puf['MARS'], drop_first = True)\n",
    "\n",
    "# E19800 and E20100 combined in CPS\n",
    "\n",
    "puf['E19800_E20100'] = puf['E19800'] + puf['E20100']\n",
    "\n",
    "# All variables shared between puf and cps, except for E01100 (crashing mnlogit), E00650 (colinear w/E00600)\n",
    "\n",
    "pred =  [\n",
    "         'DSI', 'EIC', 'MARS2', 'MARS3', 'MARS4', 'XTOT', \n",
    "         'E00200', 'E00300', 'E00400', 'E00600', 'E00800', 'E00900', \n",
    "         'E01400', 'E01500', 'E01700', 'E02100', 'E02300', 'E02400', \n",
    "         'E03150', 'E03210', 'E03240', 'E03270', 'E03300', 'E17500', \n",
    "         'E18400', 'E18500', 'E19200', 'E19800_E20100','E20400', \n",
    "         'E32800', 'F2441', 'N24'\n",
    "        ]\n",
    "\n",
    "keep = ['RECID', 'AGIR1', 'P22250'] + pred\n",
    "\n",
    "puf = puf[keep]\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "train, test = train_test_split(puf, test_size=0.2)\n",
    "\n",
    "# Sub-df's where P22250 > 0 or < 0 pos or neg for 2nd stage imputation\n",
    "\n",
    "pos_train = train.copy()[train.copy()['P22250'] > 0]\n",
    "neg_train = train.copy()[train.copy()['P22250'] < 0]\n",
    "\n",
    "pos_test =  test.copy()[test.copy()['P22250'] > 0]\n",
    "neg_test =  test.copy()[test.copy()['P22250'] < 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_Lasso = linear_model.LassoCV(cv = 10, n_jobs = -1).fit(pos_train[pred], pos_train['P22250'])\n",
    "pos_Lasso_predictions = pos_Lasso.predict(pos_test[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "861831.864777408"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_Lasso_MSE = metrics.mean_squared_error(pos_test['P22250'], pos_Lasso_predictions)\n",
    "pos_Lasso_MSE**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   11.7s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# 100 estimators\n",
    "N_ESTIMATORS = 100\n",
    "pos_rf = ensemble.RandomForestRegressor(n_estimators=N_ESTIMATORS, \n",
    "                                    min_samples_leaf=1, random_state=3, \n",
    "                                    verbose=True, \n",
    "                                    n_jobs=-1)  # Use maximum number of cores.\n",
    "pos_rf.fit(pos_train[pred], pos_train['P22250'])\n",
    "pos_rf_predictions = pos_rf.predict(pos_test[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "899732.1339124828"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_rf_MSE = metrics.mean_squared_error(pos_test['P22250'], pos_rf_predictions)\n",
    "pos_rf_MSE**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_Lasso = linear_model.LassoCV(cv = 10, n_jobs = -1).fit(neg_train[pred], neg_train['P22250'])\n",
    "neg_Lasso_predictions = neg_Lasso.predict(neg_test[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "586291.2798122863"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_Lasso_MSE = metrics.mean_squared_error(neg_test['P22250'], neg_Lasso_predictions)\n",
    "neg_Lasso_MSE**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   13.6s finished\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 100 out of 100 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "# 100 estimators\n",
    "N_ESTIMATORS = 100\n",
    "neg_rf = ensemble.RandomForestRegressor(n_estimators=N_ESTIMATORS, \n",
    "                                    min_samples_leaf=1, random_state=3, \n",
    "                                    verbose=True, \n",
    "                                    n_jobs=-1)  # Use maximum number of cores.\n",
    "neg_rf.fit(neg_train[pred], neg_train['P22250'])\n",
    "neg_rf_predictions = neg_rf.predict(neg_test[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "843195.0226865638"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_rf_MSE = metrics.mean_squared_error(neg_test['P22250'], neg_rf_predictions)\n",
    "neg_rf_MSE**0.5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
